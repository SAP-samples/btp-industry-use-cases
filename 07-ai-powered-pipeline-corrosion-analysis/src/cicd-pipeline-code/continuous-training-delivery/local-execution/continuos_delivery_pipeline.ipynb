{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80fa909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import joblib\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "from os.path import exists\n",
    "from joblib import load, dump\n",
    "from os import makedirs, environ\n",
    "import base64\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from pandas_schema import Column, Schema\n",
    "from pandas_schema.validation import InRangeValidation, InListValidation,\\\n",
    "IsDistinctValidation, DateFormatValidation, CustomElementValidation\n",
    "\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "from ai_core_sdk.models import Artifact, Status, TargetStatus, ParameterBinding, InputArtifactBinding\n",
    "\n",
    "FORMAT = \"%(asctime)s:%(name)s:%(levelname)s - %(message)s\"\n",
    "# Use filename=\"file.log\" as a param to logging to log to a file\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc84be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement logging\n",
    "#Implement all parameters\n",
    "#Implement the deployment in a different resource group\n",
    "\n",
    "# Pass artifact id to be used in the retraining or the path to register a new input dataset for the training\n",
    "# Validation of the training dataset has to be moved into the training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d6309a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Retrieving configuration from the GitHub repository.\n",
      "pipeline-corrosion-analytics pipeline-corr-data training-pipeline\n",
      "pipeline-corrosion-analytics pipelinecorrmodel server-pipeline\n",
      "1. Configuration retrieved from the GitHub repository.\n",
      "2. Creating AI API client instance.\n",
      "2. AI API client instance created.\n",
      "TEST\n",
      "id : cicd-pipeline-corrosion-analytics\n",
      "name : cicd-pipeline-corrosion-analytics\n",
      "description : CI-CD Pipelines for Pipeline Corrosion Analytics\n",
      "created_at : 2023-09-07 13:17:54\n",
      "modified_at : 2023-09-21 15:15:07\n",
      "id : pipeline-corrosion-analytics\n",
      "name : pipeline-corrosion-analytics\n",
      "description : Pipeline Corrosion Prediction\n",
      "created_at : 2023-09-13 09:58:51\n",
      "modified_at : 2023-09-14 13:11:20\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "class ct_cd_pipeline():\n",
    "    \n",
    "    def __init__(self, current_deployment_id, metric_threshold,\n",
    "                 input_artifact_id, input_artifact_path) -> None:\n",
    "\n",
    "        self.resource_group_dev = \"dev\"\n",
    "        self.resource_group_test = \"test\"\n",
    "        self.resource_group_prod = \"prod\"\n",
    "        \n",
    "        self.ai_core_v2_client = None\n",
    "        self.aic_service_key = \"./aic_service_key.json\" #To understand if this is needed\n",
    "        self.dataset_name = \"pipeline-corr-data\"\n",
    "        self.model_name = \"pipelinecorrmodel\" #Taken from the GitHub template\n",
    "        self.scenario_id = \"pipeline-corrosion-analytics\" #Taken from the GitHub template\n",
    "        self.executable_name = \"training-pipeline\" #Taken from the GitHub template\n",
    "        \n",
    "        #self.data_source_train = environ[\"DATA_SOURCE_TRAIN\"] #Path inside the container\n",
    "        #self.data_source_test = environ[\"DATA_SOURCE_TEST\"] #Path inside the container\n",
    "        self.data_source_test = \"./data/training\" #This is to get train data from local path\n",
    "        self.data_source_train = \"./data/training\" #This is to get test data from local path\n",
    "        self.dataset_path_train = input_artifact_path #Path in S3 to register a new artifact\n",
    "\n",
    "        self.current_deployment_id = current_deployment_id\n",
    "        self.serving_executable_name = \"server-pipeline\"  #Taken from the GitHub template\n",
    "        self.metric_threshold = metric_threshold\n",
    "        \n",
    "        self.artifact_resp = None\n",
    "        self.artifact_id = input_artifact_id\n",
    "        self.execution_id = None\n",
    "        self.train_config_resp = None\n",
    "        self.serve_config_resp = None\n",
    "        self.execution_resp = None\n",
    "        self.training_output = None\n",
    "        self.metric_resp = None\n",
    "        self.deployment_resp = None\n",
    "        \n",
    "        self.dataset_all = None\n",
    "        \n",
    "        \n",
    "    def get_temp_conf(self) -> None:\n",
    "\n",
    "        print(\"1. Retrieving configuration from the GitHub repository.\")\n",
    "        username = \"abc\"\n",
    "        token = \"abc\" #To be securely stored in some way\n",
    "        repo_name = \"pipeline-corrosion-repo\"\n",
    "        folder = \"solution-prod-templates\" #This must become a parameter\n",
    "        train_temp_path = folder+\"/training_template.yaml?ref=main\" #This must become a parameter\n",
    "        serve_temp_path = folder+\"/serving_template.yaml?ref=main\" #This must become a parameter\n",
    "\n",
    "        train_temp_url = \"https://api.github.com/repos/\"+username+\"/\"+repo_name+\"/contents/\"+train_temp_path\n",
    "        serve_temp_url = \"https://api.github.com/repos/\"+username+\"/\"+repo_name+\"/contents/\"+serve_temp_path\n",
    "        #print(train_temp_url, serve_temp_url)\n",
    "        \n",
    "        req_train_temp = requests.get(train_temp_url, auth = HTTPBasicAuth(username, token))\n",
    "        req_serve_temp = requests.get(serve_temp_url, auth = HTTPBasicAuth(username, token))\n",
    "        \n",
    "        if req_train_temp.status_code == requests.codes.ok:\n",
    "            #print(req_train_temp.status_code)\n",
    "            req_train_temp = req_train_temp.json()\n",
    "            content = base64.b64decode(req_train_temp['content'])\n",
    "            #print(content)\n",
    "            training_workflow = yaml.safe_load(content)\n",
    "            #print(training_workflow)\n",
    "        else:\n",
    "            print('Content was not found.') #This has to stop the execution\n",
    "            exit(1)\n",
    "        \n",
    "        if req_serve_temp.status_code == requests.codes.ok:\n",
    "            #print(req_serve_temp.status_code)\n",
    "            req_serve_temp = req_serve_temp.json()\n",
    "            content = base64.b64decode(req_serve_temp['content'])\n",
    "            #print(content)\n",
    "            serving_workflow = yaml.safe_load(content)\n",
    "            #print(serving_workflow)\n",
    "        else:\n",
    "            print('Content was not found.') #This has to stop the execution\n",
    "            exit(1)\n",
    "\n",
    "        # From the training template\n",
    "        self.scenario_id = training_workflow['metadata']['labels']['scenarios.ai.sap.com/id']\n",
    "        self.dataset_name = training_workflow['spec']['templates'][0]['inputs']['artifacts'][0]['name']\n",
    "        self.executable_name = training_workflow['metadata']['name']\n",
    "        print(self.scenario_id, self.dataset_name, self.executable_name)\n",
    "        \n",
    "        self.model_name = serving_workflow['spec']['inputs']['artifacts'][0]['name']\n",
    "        self.serving_executable_name = serving_workflow['metadata']['name']\n",
    "        print(self.scenario_id, self.model_name, self.serving_executable_name)\n",
    "        print(\"1. Configuration retrieved from the GitHub repository.\")\n",
    "\n",
    "\n",
    "    def create_api_client(self, resource_group) -> None:\n",
    "        \n",
    "        print(\"2. Creating AI API client instance.\")\n",
    "        # Your service key JSON file relative to your aicore instance\n",
    "        aic_service_key_path = self.aic_service_key\n",
    "\n",
    "        # Loads the service key file\n",
    "        with open(aic_service_key_path) as ask:\n",
    "            aic_service_key = json.load(ask)\n",
    "\n",
    "        # Creating an AI API client instance\n",
    "        self.ai_core_v2_client = AICoreV2Client(\n",
    "            base_url=aic_service_key[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\",\n",
    "            auth_url=aic_service_key[\"url\"] + \"/oauth/token\",\n",
    "            client_id=aic_service_key['clientid'],\n",
    "            client_secret=aic_service_key['clientsecret'],\n",
    "            resource_group=resource_group\n",
    "        )\n",
    "        print(\"2. AI API client instance created.\")\n",
    "        \n",
    "        \n",
    "    def csv_validation(self, df_from_csv):\n",
    "        \n",
    "        # Mean, std, min, max\n",
    "        # Statistical properties used to generate the dataset\n",
    "        v01 = [45.98, 17.29, 21, 74] # Temperature\n",
    "        v02 = [0.13, 0.1, 0.01, 0.61] # CO2 Partial Pressure\n",
    "        v03 = [7.6, 0.64, 6.21, 8.57] # pH\n",
    "        v04 = [34.31, 20.37, 2, 70] # Sulphate ion concentration\n",
    "        v05 = [3168.79, 2382.86, 66, 7571.14] # Chloride ion concentration\n",
    "        v06 = [0.42, 0.34, 0.01, 0.9] # Basic sediment and water\n",
    "        v07 = [8.54, 5.17, 0.2, 17.54] # Million Cubic Feet per day of gas\n",
    "        v08 = [684.48, 337.45, 125, 1565.97] # Barrel of Oil production per day\n",
    "        v09 = [1269.38, 1965.96, 1, 9328] # Barrel of Water production per day\n",
    "        v10 = [1.17, 0.97, 0.04, 2.79] # Iron content\n",
    "        v11 = [2404.93, 1161.44, 152.5, 4209] # Total Alkalinity as HCO_3\n",
    "        v12 = [880.93, 569.82, 65, 2050] # Operating pressure\n",
    "        v13 = [1.11, 0.79, 0.02, 2.56] # Calcium concentration\n",
    "        \n",
    "        decimal_validation = [CustomElementValidation(lambda d: isinstance(d, float), 'is not decimal')]\n",
    "        int_validation = [CustomElementValidation(lambda i: isinstance(i, int), 'is not integer')]\n",
    "        null_validation = [CustomElementValidation(lambda d: d is not None, 'this field cannot be null')]\n",
    "\n",
    "        #Maximum offset is 25% on the variables\n",
    "        schema = Schema([\n",
    "            Column('loc_id', [InRangeValidation(0,1000)]+null_validation+int_validation),\n",
    "            Column('idx', [InRangeValidation(0,1000)]+null_validation+int_validation),\n",
    "            Column('date', [DateFormatValidation('%Y-%m-%d')]+null_validation),\n",
    "            Column('corr_depth', [InRangeValidation(0,50)]+null_validation+decimal_validation),\n",
    "            Column('v01', [InRangeValidation(v01[2],v01[3]*1.25)]+null_validation+decimal_validation),\n",
    "            Column('v02', [InRangeValidation(v02[2],v02[3]*1.25)]+null_validation+decimal_validation),\n",
    "            Column('v03', [InRangeValidation(v03[2],v03[3]*1.25)]+null_validation+decimal_validation),\n",
    "            Column('v04', [InRangeValidation(v04[2],v04[3]*1.25)]+null_validation+decimal_validation),\n",
    "            Column('v05', [InRangeValidation(v05[2],v05[3]*1.25)]+null_validation+decimal_validation),\n",
    "            Column('v06', [InRangeValidation(v06[2],v06[3]*1.25)]+null_validation+decimal_validation),\n",
    "            Column('v07', [InRangeValidation(v07[2],v07[3]*1.25)]+null_validation+decimal_validation),\n",
    "            Column('v08', [InRangeValidation(v08[2],v08[3]*1.25)]+null_validation+decimal_validation),\n",
    "            Column('v09', [InRangeValidation(v09[2],v09[3]*1.25)]+null_validation+decimal_validation),\n",
    "            Column('v10', [InRangeValidation(v10[2],v10[3]*1.25)]+null_validation+decimal_validation),\n",
    "            Column('v11', [InRangeValidation(v11[2],v11[3]*1.25)]+null_validation+decimal_validation),\n",
    "            Column('v12', [InRangeValidation(v12[2],v12[3]*1.25)]+null_validation+decimal_validation),\n",
    "            Column('v13', [InRangeValidation(v13[2],v13[3]*1.25)]+null_validation+decimal_validation)\n",
    "        ])\n",
    "        \n",
    "        errors = schema.validate(df_from_csv)\n",
    "        return errors\n",
    "\n",
    "        \n",
    "    def read_and_validate_dataset(self, data_source) -> None:\n",
    "        \n",
    "        print(\"3. Reading and validating the input dataset.\")     \n",
    "        logging.info(f\"{data_source}\")\n",
    "\n",
    "        csv_files = glob.glob(os.path.join(data_source, \"*.csv\"))\n",
    "        dfs = []\n",
    "\n",
    "        for csv in csv_files:\n",
    "            df = pd.read_csv(csv)\n",
    "            dfs.append(df)\n",
    "\n",
    "        self.dataset_all = pd.concat(dfs, ignore_index=True)\n",
    "        self.dataset_all = self.dataset_all.sample(frac=1).reset_index(drop=True)\n",
    "        print(f\"No. of training examples: {self.dataset_all.shape[0]}\")\n",
    "        \n",
    "        errors = self.csv_validation(self.dataset_all)\n",
    "        if len(errors) == 0:\n",
    "            print(\"3. Dataset validation succeeded!\")\n",
    "        else:\n",
    "            print(\"3. Dataset validation failed! Number of identified issues: \"+str(len(errors)))\n",
    "            #print(\"Check the log for the details about the identified issues.\") #Logging to be implemented\n",
    "            exit(1)   \n",
    "        \n",
    "    \n",
    "    def register_artifact(self, artifact_s3_path, artifact_type, description) -> None:\n",
    "        \n",
    "        print(\"4. Registering artifact.\")\n",
    "        # Set the artifact configuration\n",
    "        artifact = {\n",
    "                \"name\": self.dataset_name,\n",
    "                \"kind\": artifact_type, #For example Artifact.Kind.DATASET\n",
    "                \"url\": \"ai://default\"+artifact_s3_path,  \n",
    "                \"description\":  description,\n",
    "                \"scenario_id\": self.scenario_id\n",
    "            }\n",
    "        # Store the artifact response to retrieve the id for the training configuration\n",
    "        self.artifact_resp = self.ai_core_v2_client.artifact.create(**artifact)\n",
    "        print(vars(self.artifact_resp))\n",
    "        \n",
    "        if self.artifact_resp.id is not None:\n",
    "            self.artifact_id = self.artifact_resp.id\n",
    "            print(self.artifact_id)\n",
    "            print(\"4. Artifact registered.\")\n",
    "        else:\n",
    "            print(\"4. Registering artifact failed!\")\n",
    "            exit(1)\n",
    "\n",
    "    \n",
    "    def create_training_conf(self) -> None:\n",
    "        \n",
    "        print(\"5. Creating training configuration.\")\n",
    "        scenarios = self.ai_core_v2_client.scenario.query()\n",
    "        \n",
    "        artifact_binding = {\n",
    "            \"key\": self.dataset_name,\n",
    "            \"artifact_id\": self.artifact_id\n",
    "        }\n",
    "\n",
    "        train_configuration = {\n",
    "            \"name\": \"pipeline-corr-train-conf\",\n",
    "            \"scenario_id\": self.scenario_id,\n",
    "            \"executable_id\": self.executable_name,\n",
    "            \"parameter_bindings\": [],\n",
    "            \"input_artifact_bindings\": [ InputArtifactBinding(**artifact_binding) ]\n",
    "        }\n",
    "\n",
    "        # Store the configuration response to access the id to create an execution\n",
    "        self.train_config_resp = self.ai_core_v2_client.configuration.create(**train_configuration)\n",
    "        print(vars(self.train_config_resp))\n",
    "        \n",
    "        if self.train_config_resp.id is not None:\n",
    "            print(\"5. Creating training configuration.\")\n",
    "        else:\n",
    "            print(\"5. Creating training configuration failed!\")\n",
    "            exit(1)\n",
    "\n",
    "    \n",
    "    def start_execution(self) -> None:\n",
    "        \n",
    "        print(\"6. Starting training execution.\")\n",
    "        self.execution_resp = self.ai_core_v2_client.execution.create(self.train_config_resp.id)\n",
    "        print(vars(self.execution_resp))\n",
    "        #Add a test to be sure it was registered properly based on the content of execution_resp\n",
    "        \n",
    "        if self.train_config_resp.id is not None:\n",
    "            print(\"6. Training execution started.\")\n",
    "        else:\n",
    "            print(\"6. Training execution failed!\")\n",
    "            exit(1)\n",
    "        \n",
    "\n",
    "    def get_execution_status(self) -> None:\n",
    "        \n",
    "        print(\"7. Checking execution status.\")\n",
    "        status = None\n",
    "        while status != Status.COMPLETED and status != Status.DEAD:\n",
    "            # Sleep for 5 secs to avoid overwhelming the API with requests\n",
    "            time.sleep(5)\n",
    "            # Clear outputs to reduce clutter\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            execution = self.ai_core_v2_client.execution.get(self.execution_resp.id)\n",
    "            status = execution.status\n",
    "            print('...... Execution status ......', flush=True)\n",
    "            print(f\"Training status: {execution.status}\")\n",
    "            print(f\"Training status details: {execution.status_details}\")\n",
    "\n",
    "        if execution.status == Status.COMPLETED:\n",
    "            print(f\"Training complete for execution [{self.execution_resp.id}]!\")\n",
    "            output_artifact = execution.output_artifacts[0]\n",
    "            self.training_output = {\n",
    "                \"id\": output_artifact.id,\n",
    "                \"name\": output_artifact.name,\n",
    "                \"url\": output_artifact.url\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Training failed for execution [{self.execution_resp.id}]!\")\n",
    "            exit(1)\n",
    "    \n",
    "    \n",
    "    def get_execution_metrics(self) -> None:\n",
    "        \n",
    "        print(\"8. Retrieving execution metrics.\")\n",
    "        #execution_resp_id = \"e0b2c7a1233a0936\" # For testing only\n",
    "        filter_string = \"executionId eq '\" + self.execution_resp.id + \"'\"\n",
    "        #filter_string = \"executionId eq '\" + execution_resp_id + \"'\"\n",
    "        self.metric_resp = self.ai_core_v2_client.metrics.query(execution_ids=self.execution_resp.id)\n",
    "        #self.metric_resp = self.ai_core_v2_client.metrics.query(execution_ids=execution_resp_id)\n",
    "\n",
    "        for m in self.metric_resp.resources:\n",
    "            for metric in m.metrics:\n",
    "                print(metric.name)\n",
    "                print(metric.value)\n",
    "        print(\"8. Execution metrics retrieved.\")\n",
    "                \n",
    "        \n",
    "    def create_serving_conf(self, resource_group) -> None:\n",
    "        \n",
    "        print(\"9. Creating deployment configuration to test the new model.\")\n",
    "        print(self.model_name, self.training_output[\"id\"])\n",
    "        self.serve_config_resp = self.ai_core_v2_client.configuration.create(\n",
    "            name = \"pipeline-corr-serving-conf\",\n",
    "            scenario_id = self.scenario_id,\n",
    "            executable_id = self.serving_executable_name,\n",
    "            input_artifact_bindings = [\n",
    "                #InputArtifactBinding(key = \"pipelinecorrmodel\",\\\n",
    "                #                     artifact_id = \"846f909d-d14a-46f5-942b-d33ed656213b\") # For testing only\n",
    "                InputArtifactBinding(key = self.model_name, artifact_id = self.training_output[\"id\"])\n",
    "            ],\n",
    "            parameter_bindings = [\n",
    "                ParameterBinding(key = \"greetmessage\", value = \"Hi AI Core server\")\n",
    "            ],\n",
    "            resource_group = resource_group\n",
    "        )\n",
    "        \n",
    "        if self.serve_config_resp.id is not None:\n",
    "            print(self.serve_config_resp.__dict__)\n",
    "            print(\"9. Deployment configuration created.\")\n",
    "        else:\n",
    "            print(\"9. Deployment configuration creation failed!\")\n",
    "            exit(1)\n",
    "\n",
    "                \n",
    "    def deploy_model(self, resource_group) -> None: #To be used to test the model deployment\n",
    "        \n",
    "        print(\"10. Deploying new model.\")\n",
    "        metrics = self.metric_resp.resources[0].metrics\n",
    "        metric_value = metrics[0].value\n",
    "        print(\"MSE: \"+str(metric_value))\n",
    "        \n",
    "        if(metric_value < self.metric_threshold): \n",
    "        \n",
    "            self.create_serving_conf(resource_group) ## Create serving configuration\n",
    "            self.deployment_resp = self.ai_core_v2_client.deployment.create(self.serve_config_resp.id)\n",
    "            print(vars(self.deployment_resp))\n",
    "            status = self.check_deployment(self.deployment_resp.id)\n",
    "            if status == Status.DEAD:\n",
    "                print(\"10. Deployment failed!\")\n",
    "                exit(1)\n",
    "        \n",
    "        else:\n",
    "            print(\"10. Deployment is not possible because of model lower accuracy!\")\n",
    "            exit(1)\n",
    "            \n",
    "    \n",
    "    def check_deployment(self, deployment_id):\n",
    "        \n",
    "        # Poll deployment status\n",
    "        status = None\n",
    "        elapsed_time = 0\n",
    "        while status != Status.RUNNING and status != Status.DEAD:\n",
    "            start = time.time()\n",
    "            time.sleep(5)\n",
    "            clear_output(wait=True)\n",
    "            deployment = self.ai_core_v2_client.deployment.get(deployment_id)\n",
    "            status = deployment.status\n",
    "            print('...... Deployment status ......', flush=True)\n",
    "            print(deployment.status)\n",
    "            print(deployment.status_details)\n",
    "            end = time.time()\n",
    "            elapsed_time += (end-start)\n",
    "            \n",
    "            if elapsed_time > 600:\n",
    "                print(\"Deployment pending for too long. Stopping...\")\n",
    "                break\n",
    "\n",
    "            if deployment.status == Status.RUNNING:\n",
    "                print(f\"Deployment with {deployment_id} complete!\")\n",
    "\n",
    "        # Allow some time for deployment URL to get ready\n",
    "        time.sleep(10)\n",
    "        return status\n",
    "\n",
    "            \n",
    "    def test_deployment(self, resource_group, deployment_id) -> None:\n",
    "        \n",
    "        print(\"11. Testing the deployment.\")\n",
    "        X, y = self.dataset_all.drop(['corr_depth','date'], axis=1),\\\n",
    "            self.dataset_all[['corr_depth']].values.ravel()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=13)\n",
    "        print(\"Number of test records: \"+str(X_test.size))\n",
    "        \n",
    "        deployment = self.ai_core_v2_client.deployment.get(deployment_id)\n",
    "        endpoint = f\"{deployment.deployment_url}/v2/predict\"\n",
    "        print(endpoint)\n",
    "\n",
    "        headers = {\n",
    "                \"Authorization\": self.ai_core_v2_client.rest_client.get_token(),\n",
    "                'ai-resource-group': resource_group,\n",
    "                \"Content-Type\": \"application/json\"}\n",
    "\n",
    "        def apply_request(row):\n",
    "            #print(row)\n",
    "            response = requests.post(endpoint, headers=headers, json=row.to_dict())\n",
    "            #print(response.json())\n",
    "            return response.json()[0]\n",
    "        \n",
    "        X_test['pred'] = X_test.apply(apply_request, axis=1)\n",
    "        #print(X_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, X_test['pred'])\n",
    "        print('Inference result:', mse)\n",
    "        \n",
    "        if mse < self.metric_threshold:\n",
    "            print(\"11. Deployment validation passed!\")\n",
    "        else:\n",
    "            print(\"11. Deployment validation failed!\") #Stop execution and pipeline\n",
    "            self.stop_deployment(resource_group)\n",
    "            exit(1)\n",
    "\n",
    "    \n",
    "    def stop_deployment(self, resource_group) -> None:\n",
    "        \n",
    "        print(\"12. Stopping the deployment.\")\n",
    "        delete_resp = self.ai_core_v2_client.deployment.modify(self.deployment_resp.id,\\\n",
    "                                                               target_status=TargetStatus.STOPPED)\n",
    "        status = self.check_deployment(delete_resp.id)\n",
    "        \n",
    "        if status == Status.STOPPED:\n",
    "            print(\"12. Deployment stopped gracefully.\")\n",
    "        else:\n",
    "            print(\"12. Something went wrong stopping the deployment!\")\n",
    "            #exit(1)\n",
    "\n",
    "    \n",
    "    def switch_model(self, resource_group) -> None:\n",
    "        \n",
    "        print(\"13. Switching the model under the current deployment.\")\n",
    "        metrics = self.metric_resp.resources[0].metrics\n",
    "        metric_value = metrics[0].value\n",
    "        print(\"MSE: \"+str(metric_value))\n",
    "        \n",
    "        if(metric_value < self.metric_threshold): \n",
    "        \n",
    "            self.create_serving_conf(resource_group)\n",
    "\n",
    "            patch_resp = self.ai_core_v2_client.deployment.modify(\n",
    "                deployment_id = self.current_deployment_id, # existing deployment\n",
    "                configuration_id = self.serve_config_resp.id, # new configuration ID\n",
    "                resource_group = resource_group\n",
    "            )\n",
    "\n",
    "            print(patch_resp.__dict__)\n",
    "            status = self.check_deployment(patch_resp.id)\n",
    "            if status == Status.RUNNING:\n",
    "                print(\"13. Deployment update completed successfully!\")\n",
    "            if status == Status.DEAD:\n",
    "                print(\"13. Deployment update failed!\")\n",
    "                exit(1)\n",
    "            \n",
    "        else:\n",
    "            print(\"13. Deployment update is not possible because of model lower accuracy!\")\n",
    "            exit(1)\n",
    "\n",
    "                \n",
    "    def run_workflow(self) -> None:\n",
    "        \"\"\"\n",
    "        Run the pipeline with all the necessary steps\n",
    "        \"\"\"\n",
    "        cond1 = self.artifact_id == \"None\" and self.dataset_path_train == \"None\"\n",
    "        cond2 = self.artifact_id != \"None\" and self.dataset_path_train != \"None\"\n",
    "        if (not(cond1 or cond2)):        \n",
    "            ## Initialize parameters with prod templates content\n",
    "            self.get_temp_conf()\n",
    "            ## Create API client\n",
    "            self.create_api_client(self.resource_group_dev) # Not needed when it will run within AI Core\n",
    "            ## Register a new input dataset if needed\n",
    "            self.test_ai_api()\n",
    "            if (self.artifact_id == \"None\" and len(self.dataset_path_train) != \"None\"):\n",
    "                self.register_artifact(self.dataset_path_train, \\\n",
    "                                       Artifact.Kind.DATASET, \"Pipeline corrosion dataset\")            \n",
    "            ## Create a new training configuration\n",
    "            #self.create_training_conf()\n",
    "            ## Start a new execution/training\n",
    "            #self.start_execution()\n",
    "            ## Get execution status\n",
    "            #self.get_execution_status()\n",
    "            ## Get the metrics of the last execution\n",
    "            #self.get_execution_metrics()\n",
    "            ## It deploys the new trained model for testing purpose\n",
    "            ##self.create_serving_conf(self.resource_group_dev) #Only for testing\n",
    "            #self.deploy_model(self.resource_group_dev)\n",
    "            ## Read and validate the test dataset\n",
    "            #self.read_and_validate_dataset(self.data_source_test)\n",
    "            ## Test the previous deployment in a test resource group\n",
    "            #self.test_deployment(self.resource_group_dev, self.deployment_resp.id)\n",
    "            #self.test_deployment(self.resource_group_dev, self.current_deployment_id) \n",
    "                                                #Only for testing without a new deployment\n",
    "                                                #The test should be performed on the model deployed for testing\n",
    "            ## Once the test is completed the deployment is stopped\n",
    "            #self.stop_deployment(self.resource_group_dev)\n",
    "            ## Update the current deployment in the prod resource group\n",
    "            #self.switch_model(self.resource_group_dev) #If the previous test is ok,\n",
    "                                                        #then it updates the current deployment\n",
    "        elif cond1:\n",
    "            print(\"Missing parameters! Input Artifact ID and path cannot be empty!\")\n",
    "        elif cond2:\n",
    "            print(\"Too many parameters! Specify the Input Artifact ID or path!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_obj = ct_cd_pipeline(\"d70167c5c9b5d723\", 0.2, \"127d9a3c-68a7-498f-9a44-0c7c64497713\", \"None\")\n",
    "    #train_obj = ct_cd_pipeline(\"d70167c5c9b5d723\", 0.2, \"None\", \"/data/training\")\n",
    "    #train_obj = ct_cd_pipeline(\"d70167c5c9b5d723\", 0.2, \"None\", \"None\")\n",
    "    #train_obj = ct_cd_pipeline(\"d70167c5c9b5d723\", 0.2,\\\n",
    "    #                           \"127d9a3c-68a7-498f-9a44-0c7c64497713\", \"/data/training\")\n",
    "    train_obj.run_workflow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a2c052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
